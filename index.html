<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yazhou Zhang</title>

    <meta name="author" content="Yazhou Zhang">
    <meta name="format-detection" content="telephone=no">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="noindex, nofollow">

    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>

        <!-- ===================== HEADER ===================== -->
        <tr>
          <td>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center" class="name">Yazhou (Harry) Zhang</p>
                  <p>
                    I am an M.S. student in Mechanical Engineering at Stanford University. My interests are in robotics,
                    with a focus on modeling & control, dexterous manipulation, and robot perception.
                  </p>

                  <p>
                    I enjoy building end-to-end robotic systems—from perception and state estimation to motion planning
                    and feedback control—and validating them in simulation and on hardware.
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:zhangyaz@stanford.edu">Email</a> &nbsp;/&nbsp;
                    <a href="cv.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://github.com/Yazhou-HZhang">GitHub</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/yazhou-zhang-761979281">LinkedIn</a>
                  </p>
                </td>

                <td style="padding:2.5%;width:37%;vertical-align:middle">
                  <div class="profile-hover">
                    <img src="media/profile_3.jpg" class="profile-img base" alt="profile photo">
                    <img src="media/profile_1.jpg" class="profile-img hover" alt="profile photo hover">
                  </div>
                </td>

              </tr>
            </table>

            <!-- ===================== INDUSTRIAL EXPERIENCE ===================== -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px">
                  <h2>Industrial Experience</h2>
                </td>
              </tr>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/xpeng/xpeng_p.jpg" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/xpeng.html">
                    <papertitle>XPENG Robotics — Humanoid Dexterous Hand Manipulation</papertitle>
                  </a><br>
                  <em>Embodied Intelligence Intern</em> | Shenzhen, China | 05/2025 – 09/2025
                  <br><br>
                  Worked on contact-rich manipulation for a humanoid dexterous hand, including compliance control,
                  optimization-based retargeting, and learning-based manipulation pipelines.
                  <br><br>
                  <!-- <a href="#">video (placeholder)</a> / <a href="#">report (placeholder)</a> -->
                </td>
              </tr>
            </table>

            <!-- ===================== RESEARCH EXPERIENCE ===================== -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px">
                  <h2>Research Experience</h2>
                </td>
              </tr>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/tendon-arm/tendon-arm_p.png" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/tendon-arm.html">
                  <papertitle>Salisbury Robotics Lab — Tendon-Actuated Robotic Arm with Adjustable Compliance</papertitle>
                  </a>
                  <br>
                  <em>Research Project</em> | Stanford University | 01/2025 – 03/2025
                  <br><br>
                  Developed impedance/torque control and stiffness perception for a tendon-driven arm, enabling
                  adaptive interaction with objects of varying stiffness.
                  <br><br>
                  <a href="https://drive.google.com/drive/folders/1BkXEn8MguvmWFfs8zLrXNlPUbEYFNDKT?usp=sharing" target="_blank">demo</a>
                </td>
              </tr>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/gait-monitoring/gait_device.jpg" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/gait-monitoring.html">
                    <papertitle>Decisionics Lab — Wearable Gait Monitoring Research</papertitle>
                  </a>
                  <br>
                  <em>Research Project</em> | University of Toronto | 05/2023 – 08/2023
                  <br><br>
                  Developed a low-cost wearable gait monitoring system, with emphasis on
                  hardware validation, signal processing, and data optimization for
                  robust real-world deployment across diverse terrains.
                  <br><br>
                  <!-- Optional links -->
                  <!-- <a href="https://..." target="_blank">demo</a> -->
                </td>
              </tr>
            </table>


            <!-- ===================== RECENT PROJECTS ===================== -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px">
                  <h2>Recent Projects</h2>
                </td>
              </tr>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">

              <!-- AA228 -->
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/autonomous-racing/autonomous-racing_p.png" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/autonomous-racing.html">
                  <papertitle>RL for Autonomous Racing with Dynamic Opponents</papertitle>
                  </a>
                  <br>
                  <em>AA228: Decision Making Under Uncertainty</em> | 09/2025 – 12/2025
                  <br><br>
                  PPO-based autonomous racing with dynamic opponents and occupancy-grid observations.
                  <br><br>
                  <a href="https://drive.google.com/drive/folders/1EBvCKC4naMYwvVxu6cOY4pFeuYfEBAK_?usp=drive_link" target="_blank">video / </a>
                  <a href="../reports/autonomous-racing.pdf" target="_blank">report</a>
                </td>
              </tr>

              <!-- Robot Perception -->
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/pick-and-place/pick-and-place_p.png" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/pick-and-place.html">
                  <papertitle>Robot Perception Pick-and-Place: Modular vs End-to-End</papertitle>
                  </a>
                  <br>
                  <em>EE227: Robot Perception</em> | 09/2025 – 12/2025
                  <br><br>
                  Compared U-Net + ICP modular perception with end-to-end action affordance learning.
                  <br><br>
                  <a href="https://drive.google.com/file/d/17B-lFORNtLnjmDKzcoUy3QajqDEYc-H8/view?usp=drive_link" target="_blank">video (modular)</a>
                  /
                  <a href="https://drive.google.com/file/d/1jhog9dQCel3yIELaJ0KyylYTpSEPAvT5/view?usp=drive_link" target="_blank">video (end-to-end)</a>

                </td>
              </tr>

              <!-- Rice Cooking -->
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/rice-manipulation/rice-manipulation_p.jpg" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/rice-manipulation.html">
                  <papertitle>Mobile Manipulation for Semi-Autonomous Rice Cooking</papertitle>
                  </a>
                  <br>
                  <em>CS225A: Experimental Robotics</em> | 03/2025 – 06/2025
                  <br><br>
                  Built a sim-to-real pipeline and hierarchical FSM integrating perception, planning, and control.
                  <br><br>
                  <a href="https://drive.google.com/file/d/10et5QLA4z91Edgjnu6dNngGsvKi-qIiU/view?usp=drive_link" target="_blank">video</a> / 
                  <a href="../reports/rice-manipulation.pdf" target="_blank">report</a>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/adaptive-ACT/adaptive_ACT_p.png" width="100%" alt="Adaptive-ACT">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/adaptive-ACT.html">
                    <papertitle>Adaptive-ACT: Adaptive Action Chunking for Manipulation</papertitle>
                  </a><br>
                  <em>CS224R: Final Project</em> | 03/2025 – 06/2025
                  <br><br>
                  Adaptive chunk-length selection on top of a frozen ACT policy using a PPO-trained selector.
                  <br><br>
                  <a href="reports/adaptive-ACT.pdf" target="_blank">report</a> /
                  <a href="reports/adaptive-ACT_poster.pdf" target="_blank">poster</a>
                </td>
              </tr>

            </table>

            <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px;width:25%">
                  <img src="media/turtlebot/turtlebot_frontier_p.png" width="100%">
                </td>
                <td style="padding:20px;width:75%">
                  <a href="projects/turtlebot-frontier-exploration.html">
                    <papertitle>TurtleBot Frontier Exploration (ROS2)</papertitle>
                  </a>
                  <br>
                  <em>Autonomous Robotics Project</em> | ROS2
                  <br><br>
                  Developed a frontier-based exploration system with LQR motion control,
                  EKF localization, and optimized navigation for autonomous mapping in
                  unknown environments.
                </td>
              </tr>
            </table> -->


            <!-- ===================== FOOTER ===================== -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
              <tr>
                <td style="padding:20px;text-align:center">
                  <p style="font-size:12px">
                    Template adapted from Jon Barron.
                  </p>
                </td>
              </tr>
            </table>

          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
